rank,pred,label,id,Conference,Year,Title,Link,Abstract,AuthorNames-Deduped,AuthorNames,AuthorAffiliation,InternalReferences,AuthorKeywords,AminerCitationCount_02-2020,AminerCitationCount_06-2020,XploreCitationCount - 2020-01,PubsCited,Award
1,0.9403451,1,119,InfoVis,2005,Graph-theoretic scagnostics,http://dx.doi.org/10.1109/INFVIS.2005.1532142,We introduce Tukey and Tukey scagnostics and develop graph-theoretic methods for implementing their procedure on large datasets.,Leland Wilkinson;Anushka Anand;Robert L. Grossman,L. Wilkinson;A. Anand;R. Grossman,"SPSS Inc., Chicago, IL, USA",10.1109/INFVIS.2003.1249006;10.1109/INFVIS.2004.3;10.1109/INFVIS.2004.15,"visualization, statistical graphics",131.0,165.0,61.0,43.0,
2,0.8569036,0,1201,InfoVis,2018,Shape-preserving Star Coordinates,http://dx.doi.org/10.1109/TVCG.2018.2865118,"Dimensionality reduction is commonly applied to multidimensional data to reduce the complexity of their analysis. In visual analysis systems, projections embed multidimensional data into 2D or 3D spaces for graphical representation. To facilitate a robust and accurate analysis, essential characteristics of the multidimensional data shall be preserved when projecting. Orthographic star coordinates is a state-of-the-art linear projection method that avoids distortion of multidimensional clusters by restricting interactive exploration to orthographic projections. However, existing numerical methods for computing orthographic star coordinates have a number of limitations when putting them into practice. We overcome these limitations by proposing the novel concept of shape-preserving star coordinates where shape preservation is assured using a superset of orthographic projections. Our scheme is explicit, exact, simple, fast, parameter-free, and stable. To maintain a valid shape-preserving star-coordinates configuration during user interaction with one of the star-coordinates axes, we derive an algorithm that only requires us to modify the configuration of one additional compensatory axis. Different design goals can be targeted by using different strategies for selecting the compensatory axis. We propose and discuss four strategies including a strategy that approximates orthographic star coordinates very well and a data-driven strategy. We further present shape-preserving morphing strategies between two shape-preserving configurations, which can be adapted for the generation of data tours. We apply our concept to multiple data analysis scenarios to document its applicability and validate its desired properties.",Vladimir Molchanov;Lars Linsen,Vladimir Molchanov;Lars Linsen,"Westfälische Wilhelms-Universität Münster, Germany;Westfälische Wilhelms-Universität Münster, Germany",10.1109/TVCG.2010.209;10.1109/TVCG.2013.182;10.1109/TVCG.2015.2467132;10.1109/TVCG.2015.2467324;10.1109/TVCG.2014.2346258,"Star coordinates,multidimensional data projection,multivariate data visualization",0.0,1.0,0.0,30.0,
3,0.8415213,0,606,InfoVis,2013,Orthographic Star Coordinates,http://dx.doi.org/10.1109/TVCG.2013.182,"Star coordinates is a popular projection technique from an nD data space to a 2D/3D visualization domain. It is defined by setting n coordinate axes in the visualization domain. Since it generally defines an affine projection, strong distortions can occur: an nD sphere can be mapped to an ellipse of arbitrary size and aspect ratio. We propose to restrict star coordinates to orthographic projections which map an nD sphere of radius r to a 2D circle of radius r. We achieve this by formulating conditions for the coordinate axes to define orthographic projections, and by running a repeated non-linear optimization in the background of every modification of the coordinate axes. This way, we define a number of orthographic interaction concepts as well as orthographic data tour sequences: a scatterplot tour, a principle component tour, and a grand tour. All concepts are illustrated and evaluated with synthetic and real data.",Dirk J. Lehmann;Holger Theisel,Dirk J. Lehmann;Holger Theisel,University of Magdeburg;University of Magdeburg,10.1109/VISUAL.1997.663916,"Start plot, multivariate visualization, visual analytics",24.0,31.0,24.0,27.0,
4,0.82508653,0,819,InfoVis,2015,A comparative study between RadViz and Star Coordinates,http://dx.doi.org/10.1109/TVCG.2015.2467324,"RadViz and star coordinates are two of the most popular projection-based multivariate visualization techniques that arrange variables in radial layouts. Formally, the main difference between them consists of a nonlinear normalization step inherent in RadViz. In this paper we show that, although RadViz can be useful when analyzing sparse data, in general this design choice limits its applicability and introduces several drawbacks for exploratory data analysis. In particular, we observe that the normalization step introduces nonlinear distortions, can encumber outlier detection, prevents associating the plots with useful linear mappings, and impedes estimating original data attributes accurately. In addition, users have greater flexibility when choosing different layouts and views of the data in star coordinates. Therefore, we suggest that analysts and researchers should carefully consider whether RadViz's normalization step is beneficial regarding the data sets' characteristics and analysis tasks.",Manuel Rubio-Sánchez;Laura Raya;Francisco Diaz;Alberto Sánchez 0001,Manuel Rubio-Sánchez;Laura Raya;Francisco Díaz;Alberto Sanchez,URJC;U-tad;UPM;URJC and CCS,10.1109/VAST.2010.5652433;10.1109/INFVIS.1998.729559;10.1109/VISUAL.1997.663916;10.1109/TVCG.2013.182;10.1109/TVCG.2014.2346258;10.1109/TVCG.2008.173,"RadViz, Star coordinates, Exploratory data analysis, Cluster analysis, Classification, Outlier detection",22.0,33.0,27.0,45.0,
5,0.8235463,0,652,InfoVis,2014,Axis Calibration for Improving Data Attribute Estimation in Star Coordinates Plots,http://dx.doi.org/10.1109/TVCG.2014.2346258,"Star coordinates is a well-known multivariate visualization method that produces linear dimensionality reduction mappings through a set of radial axes defined by vectors in an observable space. One of its main drawbacks concerns the difficulty to recover attributes of data samples accurately, which typically lie in the [0], [1] interval, given the locations of the low-dimensional embeddings and the vectors. In this paper we show that centering the data can considerably increase attribute estimation accuracy, where data values can be read off approximately by projecting embedded points onto calibrated (i.e., labeled) axes, similarly to classical statistical biplots. In addition, this idea can be coupled with a recently developed orthonormalization process on the axis vectors that prevents unnecessary distortions. We demonstrate that the combination of both approaches not only enhances the estimates, but also provides more faithful representations of the data.",Manuel Rubio-Sánchez;Alberto Sánchez 0001,Manuel Rubio-Sánchez;Alberto Sanchez,URJC;URJC,10.1109/TVCG.2010.209;10.1109/TVCG.2013.182;10.1109/VISUAL.1990.146402;10.1109/VISUAL.1997.663916,"Star Coordinates, RadViz, Biplots, Axis calibration, Attribute value estimation, Data centering, Orthographic projection",11.0,12.0,9.0,25.0,
6,0.8131656,0,1030,InfoVis,2017,"Scatterplots: Tasks, Data, and Designs",http://dx.doi.org/10.1109/TVCG.2017.2744184,"Traditional scatterplots fail to scale as the complexity and amount of data increases. In response, there exist many design options that modify or expand the traditional scatterplot design to meet these larger scales. This breadth of design options creates challenges for designers and practitioners who must select appropriate designs for particular analysis goals. In this paper, we help designers in making design choices for scatterplot visualizations. We survey the literature to catalog scatterplot-specific analysis tasks. We look at how data characteristics influence design decisions. We then survey scatterplot-like designs to understand the range of design options. Building upon these three organizations, we connect data characteristics, analysis tasks, and design choices in order to generate challenges, open questions, and example best practices for the effective design of scatterplots.",Alper Sarikaya;Michael Gleicher,Alper Sarikaya;Michael Gleicher,University of Wisconsin&#x2014;Madison;University of Wisconsin&#x2014;Madison,10.1109/TVCG.2015.2467618;10.1109/INFVIS.2005.1532136;10.1109/TVCG.2008.119;10.1109/TVCG.2011.229;10.1109/TVCG.2011.185;10.1109/TVCG.2013.124;10.1109/VAST.2012.6400486;10.1109/VAST.2010.5652460;10.1109/TVCG.2014.2346594;10.1109/TVCG.2009.122;10.1109/TVCG.2006.161;10.1109/TVCG.2007.70535;10.1109/INFVIS.2002.1173156;10.1109/TVCG.2013.187;10.1109/TVCG.2013.183;10.1109/TVCG.2014.2346983;10.1109/TVCG.2006.163;10.1109/VAST.2016.7883507;10.1109/TVCG.2011.223;10.1109/TVCG.2015.2467615;10.1109/VAST.2009.5333895;10.1109/TVCG.2013.182;10.1109/TVCG.2013.130;10.1109/TVCG.2016.2598839;10.1109/TVCG.2013.120;10.1109/TVCG.2013.153;10.1109/TVCG.2011.167;10.1109/TVCG.2007.70596;10.1109/TVCG.2010.197;10.1109/INFVIS.2005.1532142;10.1109/TVCG.2013.150;10.1109/TVCG.2010.174,"Scatterplots,task taxonomies,study of designs",6.0,19.0,11.0,76.0,
7,0.8128685,0,76,InfoVis,2004,Clutter Reduction in Multi-Dimensional Data Visualization Using Dimension Reordering,http://dx.doi.org/10.1109/INFVIS.2004.15,"Visual clutter denotes a disordered collection of graphical entities in information visualization. Clutter can obscure the structure present in the data. Even in a small dataset, clutter can make it hard for the viewer to find patterns, relationships and structure. In this paper, we define visual clutter as any aspect of the visualization that interferes with the viewer's understanding of the data, and present the concept of clutter-based dimension reordering. Dimension order is an attribute that can significantly affect a visualization's expressiveness. By varying the dimension order in a display, it is possible to reduce clutter without reducing information content or modifying the data in any way. Clutter reduction is a display-dependent task. In this paper, we follow a three-step procedure for four different visualization techniques. For each display technique, first, we determine what constitutes clutter in terms of display properties; then we design a metric to measure visual clutter in this display; finally we search for an order that minimizes the clutter in a display",Wei Peng;Matthew O. Ward;Elke A. Rundensteiner,Wei Peng;M.O. Ward;E.A. Rundensteiner,Worcester Polytechnic Institute,10.1109/INFVIS.2003.1249015;10.1109/VISUAL.1996.567800;10.1109/VISUAL.1990.146386;10.1109/INFVIS.1998.729559;10.1109/VISUAL.1999.809866;10.1109/INFVIS.1996.559215;10.1109/INFVIS.2000.885086,"Multidimensional visualization, dimension order, visual clutter, visual structure",182.0,218.0,96.0,27.0,
8,0.794709,0,206,InfoVis,2007,Weaving Versus Blending: a quantitative assessment of the information carrying capacities of two alternative methods for conveying multivariate data with color.,http://dx.doi.org/10.1109/TVCG.2007.70623,"In many applications, it is important to understand the individual values of, and relationships between, multiple related scalar variables defined across a common domain. Several approaches have been proposed for representing data in these situations. In this paper we focus on strategies for the visualization of multivariate data that rely on color mixing. In particular, through a series of controlled observer experiments, we seek to establish a fundamental understanding of the information-carrying capacities of two alternative methods for encoding multivariate information using color: color blending and color weaving. We begin with a baseline experiment in which we assess participants' abilities to accurately read numerical data encoded in six different basic color scales defined in the L*a*b* color space. We then assess participants' abilities to read combinations of 2, 3, 4 and 6 different data values represented in a common region of the domain, encoded using either color blending or color weaving. In color blending a single mixed color is formed via linear combination of the individual values in L*a*b* space, and in color weaving the original individual colors are displayed side-by-side in a high frequency texture that fills the region. A third experiment was conducted to clarify some of the trends regarding the color contrast and its effect on the magnitude of the error that was observed in the second experiment. The results indicate that when the component colors are represented side-by-side in a high frequency texture, most participants' abilities to infer the values of individual components are significantly improved, relative to when the colors are blended. Participants' performance was significantly better with color weaving particularly when more than 2 colors were used, and even when the individual colors subtended only 3 minutes of visual angle in the texture. However, the information-carrying capacity of the color weaving approach has its limits. We found that participants' abilities to accurately interpret each of the individual components in a high frequency color texture typically falls off as the number of components increases from 4 to 6. We found no significant advantages, in either color blending or color weaving, to using color scales based on component hues thatare more widely separated in the L*a*b* color space. Furthermore, we found some indications that extra difficulties may arise when opponent hues are employed.",Haleh Hagh-Shenas;Sunghee Kim;Victoria Interrante;Christopher G. Healey,Haleh Hagh-Shenas;Sunghee Kim;Victoria Interrante;Christopher Healey,Boston Scientific;Gettysburg College;University of Minnesota;North Carolina State University,10.1109/INFVIS.2005.1532140;10.1109/VISUAL.2003.1250362;10.1109/VISUAL.1999.809905;10.1109/INFVIS.2005.1532137,"Color, perception, visualization, color weaving, color blending",1.0,0.0,36.0,14.0,
9,0.77300656,0,456,SciVis,2012,Analysis of Streamline Separation at Infinity Using Time-Discrete Markov Chains,http://dx.doi.org/10.1109/TVCG.2012.198,"Existing methods for analyzing separation of streamlines are often restricted to a finite time or a local area. In our paper we introduce a new method that complements them by allowing an infinite-time-evaluation of steady planar vector fields. Our algorithm unifies combinatorial and probabilistic methods and introduces the concept of separation in time-discrete Markov-Chains. We compute particle distributions instead of the streamlines of single particles. We encode the flow into a map and then into a transition matrix for each time direction. Finally, we compare the results of our grid-independent algorithm to the popular Finite-Time-Lyapunov-Exponents and discuss the discrepancies.",Wieland Reich;Gerik Scheuermann,Wieland Reich;Gerik Scheuermann,University of Leipzig;University of Leipzig,10.1109/VISUAL.1999.809896,"Vector field topology, flow visualization, feature extraction, uncertainty",2.0,3.0,2.0,31.0,
10,0.7716653,0,122,InfoVis,2005,A note on space-filling visualizations and space-filling curves,http://dx.doi.org/10.1109/INFVIS.2005.1532145,"A recent line of treemap research has focused on layout algorithms that optimize properties such as stability, preservation of ordering information, and aspect ratio of rectangles. No ideal treemap layout algorithm has been found, and so it is natural to explore layouts that produce nonrectangular regions. This note describes a connection between space-filling visualizations and the mathematics of space-filling curves, and uses that connection to characterize a family of layout algorithms which produce nonrectangular regions but enjoy geometric continuity under changes to the data and legibility even for highly unbalanced trees.",Martin Wattenberg,M. Wattenberg,"IBM Res., White Plains, NY, USA",10.1109/INFVIS.2001.963283;10.1109/INFVIS.2002.1173152,Hierarchy Visualization,51.0,56.0,18.0,15.0,
11,0.7655117,0,1161,SciVis,2018,A Study of the Trade-off Between Reducing Precision and Reducing Resolution for Data Analysis and Visualization,http://dx.doi.org/10.1109/TVCG.2018.2864853,"There currently exist two dominant strategies to reduce data sizes in analysis and visualization: reducing the precision of the data, e.g., through quantization, or reducing its resolution, e.g., by subsampling. Both have advantages and disadvantages and both face fundamental limits at which the reduced information ceases to be useful. The paper explores the additional gains that could be achieved by combining both strategies. In particular, we present a common framework that allows us to study the trade-off in reducing precision and/or resolution in a principled manner. We represent data reduction schemes as progressive streams of bits and study how various bit orderings such as by resolution, by precision, etc., impact the resulting approximation error across a variety of data sets as well as analysis tasks. Furthermore, we compute streams that are optimized for different tasks to serve as lower bounds on the achievable error. Scientific data management systems can use the results presented in this paper as guidance on how to store and stream data to make efficient use of the limited storage and bandwidth in practice.",Duong Hoang;Pavol Klacansky;Harsh Bhatia;Peer-Timo Bremer;Peter Lindstrom;Valerio Pascucci,Duong Hoang;Pavol Klacansky;Harsh Bhatia;Peer-Timo Bremer;Peter Lindstrom;Valerio Pascucci,"SCI Institute, University of Utah, USA;SCI Institute, University of Utah, USA;Lawrence Livemore National Laboratory, USA;Lawrence Livemore National Laboratory, USA;Lawrence Livemore National Laboratory, USA;SCI Institute, University of Utah, USA",10.1109/TVCG.2009.194;10.1109/TVCG.2007.70516;10.1109/VISUAL.2002.1183757;10.1109/TVCG.2012.240;10.1109/VISUAL.1999.809908;10.1109/TVCG.2014.2346458;10.1109/TVCG.2006.143;10.1109/VISUAL.2004.51;10.1109/VISUAL.2003.1250385;10.1109/TVCG.2011.214;10.1109/TVCG.2012.274;10.1109/TVCG.2015.2467412,"data compression,bit ordering,multi-resolution,data analysis",,1.0,0.0,70.0,
12,0.7496799,0,729,VAST,2014,Visual Abstraction and Exploration of Multi-class Scatterplots,http://dx.doi.org/10.1109/TVCG.2014.2346594,"Scatterplots are widely used to visualize scatter dataset for exploring outliers, clusters, local trends, and correlations. Depicting multi-class scattered points within a single scatterplot view, however, may suffer from heavy overdraw, making it inefficient for data analysis. This paper presents a new visual abstraction scheme that employs a hierarchical multi-class sampling technique to show a feature-preserving simplification. To enhance the density contrast, the colors of multiple classes are optimized by taking the multi-class point distributions into account. We design a visual exploration system that supports visual inspection and quantitative analysis from different perspectives. We have applied our system to several challenging datasets, and the results demonstrate the efficiency of our approach.",Haidong Chen;Wei Chen 0001;Honghui Mei;Zhiqi Liu;Kun Zhou;Weifeng Chen 0002;Wentao Gu;Kwan-Liu Ma,Haidong Chen;Wei Chen;Honghui Mei;Zhiqi Liu;Kun Zhou;Weifeng Chen;Wentao Gu;Kwan-Liu Ma,State Key Lab of CAD&CG;State Key Lab of CAD&CG;State Key Lab of CAD&CG;State Key Lab of CAD&CG;State Key Lab of CAD&CG;Zhejiang University of Finance & Economics;Zhejiang GongShang University;University of California at Davis,10.1109/TVCG.2013.150;10.1109/TVCG.2008.119;10.1109/VISUAL.1998.745301;10.1109/TVCG.2008.120;10.1109/TVCG.2010.197;10.1109/TVCG.2006.187;10.1109/TVCG.2007.70623;10.1109/TVCG.2013.180;10.1109/INFVIS.2004.52;10.1109/VAST.2010.5652460;10.1109/TVCG.2009.112;10.1109/TVCG.2009.122;10.1109/TVCG.2011.181;10.1109/TVCG.2012.238;10.1109/TVCG.2010.176;10.1109/TVCG.2013.212;10.1109/TVCG.2011.261;10.1109/TVCG.2008.153;10.1109/TVCG.2013.183,"Scatterplot, overdraw reduction, sampling, visual abstraction",20.0,36.0,41.0,48.0,
13,0.73817056,0,289,InfoVis,2009,Interactive Dimensionality Reduction Through User-defined Combinations of Quality Metrics,http://dx.doi.org/10.1109/TVCG.2009.153,"Multivariate data sets including hundreds of variables are increasingly common in many application areas. Most multivariate visualization techniques are unable to display such data effectively, and a common approach is to employ dimensionality reduction prior to visualization. Most existing dimensionality reduction systems focus on preserving one or a few significant structures in data. For many analysis tasks, however, several types of structures can be of high significance and the importance of a certain structure compared to the importance of another is often task-dependent. This paper introduces a system for dimensionality reduction by combining user-defined quality metrics using weight functions to preserve as many important structures as possible. The system aims at effective visualization and exploration of structures within large multivariate data sets and provides enhancement of diverse structures by supplying a range of automatic variable orderings. Furthermore it enables a quality-guided reduction of variables through an interactive display facilitating investigation of trade-offs between loss of structure and the number of variables to keep. The generality and interactivity of the system is demonstrated through a case scenario.",Sara Johansson;Jimmy Johansson,Sara Johansson;Jimmy Johansson,,10.1109/INFVIS.2005.1532142;10.1109/INFVIS.2003.1249015;10.1109/INFVIS.1998.729559;10.1109/TVCG.2006.161;10.1109/INFVIS.2004.60;10.1109/INFVIS.2004.3;10.1109/INFVIS.2004.71;10.1109/TVCG.2008.138;10.1109/INFVIS.2004.15,"dimensionality reduction, interactivity, quality metrics, variable ordering",,,75.0,27.0,
14,0.73185146,0,418,InfoVis,2011,Quality Metrics in High-Dimensional Data Visualization: An Overview and Systematization,http://dx.doi.org/10.1109/TVCG.2011.229,"In this paper, we present a systematization of techniques that use quality metrics to help in the visual exploration of meaningful patterns in high-dimensional data. In a number of recent papers, different quality metrics are proposed to automate the demanding search through large spaces of alternative visualizations (e.g., alternative projections or ordering), allowing the user to concentrate on the most promising visualizations suggested by the quality metrics. Over the last decade, this approach has witnessed a remarkable development but few reflections exist on how these methods are related to each other and how the approach can be developed further. For this purpose, we provide an overview of approaches that use quality metrics in high-dimensional data visualization and propose a systematization based on a thorough literature review. We carefully analyze the papers and derive a set of factors for discriminating the quality metrics, visualization techniques, and the process itself. The process is described through a reworked version of the well-known information visualization pipeline. We demonstrate the usefulness of our model by applying it to several existing approaches that use quality metrics, and we provide reflections on implications of our model for future research.",Enrico Bertini,Enrico Bertini;Andrada Tatu;Daniel Keim,University of Konstanz,10.1109/INFVIS.2005.1532145;10.1109/VAST.2010.5652433;10.1109/VAST.2006.261423;10.1109/TVCG.2010.184;10.1109/TVCG.2010.179;10.1109/INFVIS.2004.15;10.1109/TVCG.2006.161;10.1109/TVCG.2007.70515;10.1109/INFVIS.2005.1532142;10.1109/VISUAL.1990.146402;10.1109/INFVIS.2003.1249006;10.1109/VISUAL.1990.146386;10.1109/TVCG.2006.138;10.1109/INFVIS.2004.59;10.1109/VAST.2009.5332628;10.1109/INFVIS.2003.1249015;10.1109/VAST.2010.5652450;10.1109/TVCG.2007.70535;10.1109/INFVIS.1998.729559;10.1109/INFVIS.2000.885092;10.1109/INFVIS.2004.3;10.1109/TVCG.2009.153;10.1109/INFVIS.1997.636794,"Quality Metrics, High-Dimensional Data Visualization",119.0,138.0,122.0,60.0,
15,0.7112626,0,578,InfoVis,2013,Dimension Projection Matrix/Tree: Interactive Subspace Visual Exploration and Analysis of High Dimensional Data,http://dx.doi.org/10.1109/TVCG.2013.150,"For high-dimensional data, this work proposes two novel visual exploration methods to gain insights into the data aspect and the dimension aspect of the data. The first is a Dimension Projection Matrix, as an extension of a scatterplot matrix. In the matrix, each row or column represents a group of dimensions, and each cell shows a dimension projection (such as MDS) of the data with the corresponding dimensions. The second is a Dimension Projection Tree, where every node is either a dimension projection plot or a Dimension Projection Matrix. Nodes are connected with links and each child node in the tree covers a subset of the parent node's dimensions or a subset of the parent node's data items. While the tree nodes visualize the subspaces of dimensions or subsets of the data items under exploration, the matrix nodes enable cross-comparison between different combinations of subspaces. Both Dimension Projection Matrix and Dimension Project Tree can be constructed algorithmically through automation, or manually through user interaction. Our implementation enables interactions such as drilling down to explore different levels of the data, merging or splitting the subspaces to adjust the matrix, and applying brushing to select data clusters. Our method enables simultaneously exploring data correlation and dimension correlation for data with high dimensions.",Xiaoru Yuan;Donghao Ren;Zuchao Wang;Cong Guo,Xiaoru Yuan;Donghao Ren;Zuchao Wang;Cong Guo,"Key Laboratory of Machine Perception (Ministry of Education) and School of EECS, Peking University;Key Laboratory of Machine Perception (Ministry of Education) and School of EECS, Peking University;Key Laboratory of Machine Perception (Ministry of Education) and School of EECS, Peking University;Key Laboratory of Machine Perception (Ministry of Education) and School of EECS, Peking University",10.1109/INFVIS.2005.1532142;10.1109/TVCG.2009.179;10.1109/TVCG.2010.138;10.1109/INFVIS.2003.1249015;10.1109/VISUAL.1990.146402;10.1109/VAST.2012.6400488;10.1109/VISUAL.1997.663866;10.1109/VISUAL.1995.485140;10.1109/TVCG.2010.184;10.1109/TVCG.2009.128;10.1109/VAST.2006.261422;10.1109/VISUAL.1999.809866;10.1109/INFVIS.2004.60;10.1109/INFVIS.2004.3;10.1109/INFVIS.2004.71;10.1109/TVCG.2009.153;10.1109/TVCG.2008.153;10.1109/INFVIS.2002.1173151,"High dimensional data, hierarchical visualization, sub-dimensional space, user interaction, subspace, tree, matrix",42.0,55.0,46.0,43.0,
16,0.70919466,0,719,SciVis,2014,Fixed-Rate Compressed Floating-Point Arrays,http://dx.doi.org/10.1109/TVCG.2014.2346458,"Current compression schemes for floating-point data commonly take fixed-precision values and compress them to a variable-length bit stream, complicating memory management and random access. We present a fixed-rate, near-lossless compression scheme that maps small blocks of 4&lt;sup&gt;d&lt;/sup&gt; values in d dimensions to a fixed, user-specified number of bits per block, thereby allowing read and write random access to compressed floating-point data at block granularity. Our approach is inspired by fixed-rate texture compression methods widely adopted in graphics hardware, but has been tailored to the high dynamic range and precision demands of scientific applications. Our compressor is based on a new, lifted, orthogonal block transform and embedded coding, allowing each per-block bit stream to be truncated at any point if desired, thus facilitating bit rate selection using a single compression scheme. To avoid compression or decompression upon every data access, we employ a software write-back cache of uncompressed blocks. Our compressor has been designed with computational simplicity and speed in mind to allow for the possibility of a hardware implementation, and uses only a small number of fixed-point arithmetic operations per compressed value. We demonstrate the viability and benefits of lossy compression in several applications, including visualization, quantitative data analysis, and numerical simulation.",Peter Lindstrom,Peter Lindstrom,"Center for Applied Scientific Computing, Lawrence Livermore National Laboratory",10.1109/TVCG.2006.143;10.1109/VISUAL.2001.964531;10.1109/TVCG.2006.186;10.1109/VISUAL.2001.964520;10.1109/VISUAL.2003.1250385;10.1109/TVCG.2012.209;10.1109/TVCG.2007.70516;10.1109/TVCG.2012.194;10.1109/VISUAL.1996.568138,"Data compression, floating-point arrays, orthogonal block transform, embedded coding",47.0,98.0,95.0,50.0,
17,0.69401085,1,1059,VAST,2017,Visualizing Big Data Outliers Through Distributed Aggregation,http://dx.doi.org/10.1109/TVCG.2017.2744685,"Visualizing outliers in massive datasets requires statistical pre-processing in order to reduce the scale of the problem to a size amenable to rendering systems like D3, Plotly or analytic systems like R or SAS. This paper presents a new algorithm, called hdoutliers , for detecting multidimensional outliers. It is unique for a) dealing with a mixture of categorical and continuous variables, b) dealing with big-p (many columns of data), c) dealing with big-n (many rows of data), d) dealing with outliers that mask other outliers, and e) dealing consistently with unidimensional and multidimensional datasets. Unlike ad hoc methods found in many machine learning papers, hdoutliers is based on a distributional model that allows outliers to be tagged with a probability. This critical feature reduces the likelihood of false discoveries.",Leland Wilkinson,Leland Wilkinson,H2O.aiUIC,10.1109/INFVIS.2004.68;10.1109/TVCG.2010.197;10.1109/TVCG.2014.2346572;10.1109/INFVIS.2005.1532138;10.1109/VAST.2012.6400487;10.1109/TVCG.2006.170;10.1109/INFVIS.2003.1249016;10.1109/INFVIS.2005.1532142,"Outliers,Anomalies",0.0,13.0,5.0,84.0,
18,0.68929756,0,797,InfoVis,2015,Optimal Sets of Projections of High-Dimensional Data,http://dx.doi.org/10.1109/TVCG.2015.2467132,"Finding good projections of n-dimensional datasets into a 2D visualization domain is one of the most important problems in Information Visualization. Users are interested in getting maximal insight into the data by exploring a minimal number of projections. However, if the number is too small or improper projections are used, then important data patterns might be overlooked. We propose a data-driven approach to find minimal sets of projections that uniquely show certain data patterns. For this we introduce a dissimilarity measure of data projections that discards affine transformations of projections and prevents repetitions of the same data patterns. Based on this, we provide complete data tours of at most n/2 projections. Furthermore, we propose optimal paths of projection matrices for an interactive data exploration. We illustrate our technique with a set of state-of-the-art real high-dimensional benchmark datasets.",Dirk J. Lehmann;Holger Theisel,Dirk J. Lehmann;Holger Theisel,University of Magdeburg;University of Magdeburg,10.1109/VAST.2010.5652433;10.1109/VAST.2011.6102437;10.1109/TVCG.2011.229;10.1109/VISUAL.1997.663916;10.1109/TVCG.2011.220;10.1109/TVCG.2013.182;10.1109/TVCG.2010.207;10.1109/VAST.2006.261423;10.1109/INFVIS.2005.1532142,"Multivariate Projections, Star Coordinates, Radial Visualization, High-dimensional Data",14.0,20.0,21.0,29.0,
19,0.688861,0,133,InfoVis,2006,Dynamic Map Labeling,http://dx.doi.org/10.1109/TVCG.2006.136,"We address the problem of filtering, selecting and placing labels on a dynamic map, which is characterized by continuous zooming and panning capabilities. This consists of two interrelated issues. The first is to avoid label popping and other artifacts that cause confusion and interrupt navigation, and the second is to label at interactive speed. In most formulations the static map labeling problem is NP-hard, and a fast approximation might have O(n log n) complexity. Even this is too slow during interaction, when the number of labels shown can be several orders of magnitude less than the number in the map. In this paper we introduce a set of desiderata for ""consistent"" dynamic map labeling, which has qualities desirable for navigation. We develop a new framework for dynamic labeling that achieves the desiderata and allows for fast interactive display by moving all of the selection and placement decisions into the preprocessing phase. This framework is general enough to accommodate a variety of selection and placement algorithms. It does not appear possible to achieve our desiderata using previous frameworks. Prior to this paper, there were no formal models of dynamic maps or of dynamic labels; our paper introduces both. We formulate a general optimization problem for dynamic map labeling and give a solution to a simple version of the problem. The simple version is based on label priorities and a versatile and intuitive class of dynamic label placements we call ""invariant point placements"". Despite these restrictions, our approach gives a useful and practical solution. Our implementation is incorporated into the G-Vis system which is a full-detail dynamic map of the continental USA. This demo is available through any browser",Ken Been;Eli Daiches;Chee-Keng Yap,Ken Been;Eli Daiches;Chee Yap,Yeshiva University;Yeshiva University;New York University,,"Map labeling, dynamic maps, human-computer interface, label placement, label selection, label filtering, label consistency,computational cartography, GIS, HCI, realtime, preprocessing",62.0,79.0,52.0,32.0,
20,0.67975914,1,723,VAST,2014,Transforming Scagnostics to Reveal Hidden Features,http://dx.doi.org/10.1109/TVCG.2014.2346572,"Scagnostics (Scatterplot Diagnostics) were developed by Wilkinson et al. based on an idea of Paul and John Tukey, in order to discern meaningful patterns in large collections of scatterplots. The Tukeys' original idea was intended to overcome the impediments involved in examining large scatterplot matrices (multiplicity of plots and lack of detail). Wilkinson's implementation enabled for the first time scagnostics computations on many points as well as many plots. Unfortunately, scagnostics are sensitive to scale transformations. We illustrate the extent of this sensitivity and show how it is possible to pair statistical transformations with scagnostics to enable discovery of hidden structures in data that are not discernible in untransformed visualizations.",Tommy Dang;Leland Wilkinson,Tuan Nhon Dang;Leland Wilkinson,"Department of Computer Science, University of Illinois at Chicago;Department of Computer Science, Skytree Software Inc.",10.1109/TVCG.2006.163;10.1109/INFVIS.2005.1532142;10.1109/TVCG.2013.187;10.1109/TVCG.2011.167;10.1109/VAST.2006.261423;10.1109/TVCG.2010.184;10.1109/VAST.2011.6102437;10.1109/VAST.2007.4389006,"Scagnostics, Scatterplot matrix, Transformation, High-Dimensional Visual Analytics",6.0,12.0,11.0,44.0,
21,0.6768527,0,397,InfoVis,2011,D³ Data-Driven Documents,http://dx.doi.org/10.1109/TVCG.2011.185,"Data-Driven Documents (D3) is a novel representation-transparent approach to visualization for the web. Rather than hide the underlying scenegraph within a toolkit-specific abstraction, D3 enables direct inspection and manipulation of a native representation: the standard document object model (DOM). With D3, designers selectively bind input data to arbitrary document elements, applying dynamic transforms to both generate and modify content. We show how representational transparency improves expressiveness and better integrates with developer tools than prior approaches, while offering comparable notational efficiency and retaining powerful declarative components. Immediate evaluation of operators further simplifies debugging and allows iterative development. Additionally, we demonstrate how D3 transforms naturally enable animation and interaction with dramatic performance improvements over intermediate representations.",Michael Bostock;Vadim Ogievetsky;Jeffrey Heer,Michael Bostock;Vadim Ogievetsky;Jeffrey Heer,,10.1109/INFVIS.2000.885091;10.1109/INFVIS.2000.885098;10.1109/TVCG.2010.144;10.1109/TVCG.2009.174;10.1109/INFVIS.2004.12;10.1109/TVCG.2006.178;10.1109/INFVIS.2005.1532122;10.1109/TVCG.2008.166;10.1109/INFVIS.2004.64;10.1109/TVCG.2007.70539,"Information visualization, user interfaces, toolkits, 2D graphics",1167.0,1537.0,992.0,41.0,
22,0.67419297,0,557,SciVis,2013,Adaptive Refinement of the Flow Map Using Sparse Samples,http://dx.doi.org/10.1109/TVCG.2013.128,"We present a new efficient and scalable method for the high quality reconstruction of the flow map from sparse samples. The flow map describes the transport of massless particles along the flow. As such, it is a fundamental concept in the analysis of transient flow phenomena and all so-called Lagrangian flow visualization techniques require its approximation. The flow map is generally obtained by integrating a dense 1D, 2D, or 3D set of particles across the domain of definition of the flow. Despite its embarrassingly parallel nature, this computation creates a performance bottleneck in the analysis of large-scale datasets that existing adaptive techniques alleviate only partially. Our iterative approximation method significantly improves upon the state of the art by precisely modeling the flow behavior around automatically detected geometric structures embedded in the flow, thus effectively restricting the sampling effort to interesting regions. Our data reconstruction is based on a modified version of Sibson's scattered data interpolation and allows us at each step to offer an intermediate dense approximation of the flow map and to seamlessly integrate regions that will be further refined in subsequent steps. We present a quantitative and qualitative evaluation of our method on different types of flow datasets and offer a detailed comparison with existing techniques.",Samer S. Barakat;Xavier Tricoche,Samer S. Barakat;Xavier Tricoche,Purdue University;Purdue University,10.1109/TVCG.2009.190;10.1109/TVCG.2008.133;10.1109/TVCG.2007.70554;10.1109/TVCG.2007.70551,"Lagrangian flow visualization, flow map, edge features, scattered data interpolation, sparse sampling, adaptive refinement, parallel reconstruction",9.0,13.0,14.0,40.0,HM
23,0.6700181,0,106,InfoVis,2005,Voronoi treemaps,http://dx.doi.org/10.1109/INFVIS.2005.1532128,"Treemaps are a well known method for the visualization of attributed hierarchical data. Previously proposed treemap layout algorithms are limited to rectangular shapes, which cause problems with the aspect ratio of the rectangles as well as with identifying the visualized hierarchical structure. The approach of Voronoi treemaps presented in this paper eliminates these problems through enabling subdivisions of and in polygons. Additionally, this allows for creating treemap visualizations within areas of arbitrary shape, such as triangles and circles, thereby enabling a more flexible adaptation of treemaps for a wider range of applications.",Michael Balzer;Oliver Deussen,M. Balzer;O. Deussen,"Dept. of Comput. & Inf. Sci., Konstanz Univ., Germany;Dept. of Comput. & Inf. Sci., Konstanz Univ., Germany",10.1109/INFVIS.2004.19;10.1109/INFVIS.2001.963283;10.1109/VISUAL.1991.175815;10.1109/VISUAL.2004.13;10.1109/VISUAL.1992.235217;10.1109/INFVIS.1999.801860,"Voronoi Treemaps, Information Visualization, Hierarchies, Trees, Treemaps, Voronoi Tessellations",104.0,118.0,37.0,27.0,
24,0.6684156,0,355,InfoVis,2010,Uncovering Strengths and Weaknesses of Radial Visualizations---an Empirical Approach,http://dx.doi.org/10.1109/TVCG.2010.209,"Radial visualizations play an important role in the information visualization community. But the decision to choose a radial coordinate system is rather based on intuition than on scientific foundations. The empirical approach presented in this paper aims at uncovering strengths and weaknesses of radial visualizations by comparing them to equivalent ones in Cartesian coordinate systems. We identified memorizing positions of visual elements as a generic task when working with visualizations. A first study with 674 participants provides a broad data spectrum for exploring differences between the two visualization types. A second, complementing study with fewer participants focuses on further questions raised by the first study. Our findings document that Cartesian visualizations tend to outperform their radial counterparts especially with respect to answer times. Nonetheless, radial visualization seem to be more appropriate for focusing on a particular data dimension.",Stephan Diehl 0001;Fabian Beck 0001;Michael Burch,Stephan Diehl;Fabian Beck;Michael Burch,University of Trier;University of Trier;University of Stuttgart,10.1109/INFVIS.2004.70;10.1109/INFVIS.2001.963291;10.1109/VISUAL.1997.663916;10.1109/INFVIS.2001.963291,"Radial visualization, user study, visual memory",38.0,0.0,30.0,19.0,
25,0.66369504,0,96,InfoVis,2004,Uncovering Clusters in Crowded Parallel Coordinates Visualizations,http://dx.doi.org/10.1109/INFVIS.2004.68,"The one-to-one strategy of mapping each single data item into a graphical marker adopted in many visualization techniques has limited usefulness when the number of records and/or the dimensionality of the data set are very high. In this situation, the strong overlapping of graphical markers severely hampers the user's ability to identify patterns in the data from its visual representation. We tackle this problem here with a strategy that computes frequency or density information from the data set, and uses such information in parallel coordinates visualizations to filter out the information to be presented to the user, thus reducing visual clutter and allowing the analyst to observe relevant patterns in the data. The algorithms to construct such visualizations, and the interaction mechanisms supported, inspired by traditional image processing techniques such as grayscale manipulation and thresholding are also presented. We also illustrate how such algorithms can assist users to effectively identify clusters in very noisy large data sets",Almir Olivette Artero;Maria Cristina Ferreira de Oliveira;Haim Levkowitz,A.O. Artero;M.C.F. de Oliveira;H. Levkowitz,University of S&#227;o Paulo,10.1109/VISUAL.1994.346302,"information visualization, visual clustering, density-based visualization, visual data mining",120.0,130.0,67.0,17.0,
26,0.6620053,0,706,SciVis,2014,Escape Maps,http://dx.doi.org/10.1109/TVCG.2014.2346442,"We present a technique to visualize the streamline-based mapping between the boundary of a simply-connected subregion of arbitrary 3D vector fields. While the streamlines are seeded on one part of the boundary, the remaining part serves as escape border. Hence, the seeding part of the boundary represents a map of streamline behavior, indicating if streamlines reach the escape border or not. Since the resulting maps typically exhibit a very fine and complex structure and are thus not amenable to direct sampling, our approach instead aims at topologically consistent extraction of their boundary. We show that isocline surfaces of the projected vector field provide a robust basis for stream-surface-based extraction of these boundaries. The utility of our technique is demonstrated in the context of transport processes using vector field data from different domains.",Gustavo Mello Machado;Filip Sadlo;Thomas Müller 0005;Thomas Ertl,Gustavo Machado;Filip Sadlo;Thomas Müller;Thomas Ertl,"University of Stuttgart, Germany;University of Stuttgart, Germany;University of Stuttgart, Germany;University of Stuttgart, Germany",10.1109/VISUAL.1991.175773;10.1109/VISUAL.1992.235211;10.1109/VISUAL.2003.1250376,"Streamline behavior, vector field topology, isocline surfaces, coronal hole extraction",,,1.0,30.0,
27,0.6599837,0,581,InfoVis,2013,Empirical Guidance on Scatterplot and Dimension Reduction Technique Choices,http://dx.doi.org/10.1109/TVCG.2013.153,"To verify cluster separation in high-dimensional data, analysts often reduce the data with a dimension reduction (DR) technique, and then visualize it with 2D Scatterplots, interactive 3D Scatterplots, or Scatterplot Matrices (SPLOMs). With the goal of providing guidance between these visual encoding choices, we conducted an empirical data study in which two human coders manually inspected a broad set of 816 scatterplots derived from 75 datasets, 4 DR techniques, and the 3 previously mentioned scatterplot techniques. Each coder scored all color-coded classes in each scatterplot in terms of their separability from other classes. We analyze the resulting quantitative data with a heatmap approach, and qualitatively discuss interesting scatterplot examples. Our findings reveal that 2D scatterplots are often 'good enough', that is, neither SPLOM nor interactive 3D adds notably more cluster separability with the chosen DR technique. If 2D is not good enough, the most promising approach is to use an alternative DR technique in 2D. Beyond that, SPLOM occasionally adds additional value, and interactive 3D rarely helps but often hurts in terms of poorer class separation and usability. We summarize these results as a workflow model and implications for design. Our results offer guidance to analysts during the DR exploration process.",Michael Sedlmair;Tamara Munzner;Melanie Tory,Michael Sedlmair;Tamara Munzner;Melanie Tory,University of Vienna;University of British Columbia;University of Victoria,10.1109/TVCG.2009.127;10.1109/TVCG.2011.229;10.1109/TVCG.2007.70596;10.1109/INFVIS.2005.1532142;10.1109/INFVIS.1997.636793;10.1109/VAST.2010.5652392;10.1109/VAST.2012.6400490;10.1109/TVCG.2008.109;10.1109/VAST.2009.5332628,"Dimensionality reduction, scatterplots, quantitative study",53.0,76.0,60.0,0.0,
28,0.6558811,0,610,InfoVis,2013,Selecting the Aspect Ratio of a Scatter Plot Based on Its Delaunay Triangulation,http://dx.doi.org/10.1109/TVCG.2013.187,"Scatter plots are diagrams that visualize two-dimensional data as sets of points in the plane. They allow users to detect correlations and clusters in the data. Whether or not a user can accomplish these tasks highly depends on the aspect ratio selected for the plot, i.e., the ratio between the horizontal and the vertical extent of the diagram. We argue that an aspect ratio is good if the Delaunay triangulation of the scatter plot at this aspect ratio has some nice geometric property, e.g., a large minimum angle or a small total edge length. More precisely, we consider the following optimization problem. Given a set Q of points in the plane, find a scale factor s such that scaling the x-coordinates of the points in Q by s and the y-coordinates by 1=s yields a point set P(s) that optimizes a property of the Delaunay triangulation of P(s), over all choices of s. We present an algorithm that solves this problem efficiently and demonstrate its usefulness on real-world instances. Moreover, we discuss an empirical test in which we asked 64 participants to choose the aspect ratios of 18 scatter plots. We tested six different quality measures that our algorithm can optimize. In conclusion, minimizing the total edge length and minimizing what we call the 'uncompactness' of the triangles of the Delaunay triangulation yielded the aspect ratios that were most similar to those chosen by the participants in the test.",Martin Fink 0001;Jan-Henrik Haunert;Joachim Spoerhase;Alexander Wolff 0001,Martin Fink;Jan-Henrik Haunert;Joachim Spoerhase;Alexander Wolff,"Lehrstuhl I, Institut f&#x00FC;r Informatik, Universit&#x00C2;&#x00A8;at W&#x00FC;rzburg;Lehrstuhl I, Institut f&#x00FC;r Informatik, Universit&#x00C2;&#x00A8;at W&#x00FC;rzburg;Lehrstuhl I, Institut f&#x00FC;r Informatik, Universit&#x00C2;&#x00A8;at W&#x00FC;rzburg;Lehrstuhl I, Institut f&#x00FC;r Informatik, Universit&#x00C2;&#x00A8;at W&#x00FC;rzburg",10.1109/TVCG.2006.163;10.1109/TVCG.2012.196;10.1109/TVCG.2011.167,"Scatter plot, aspect ratio, Delaunay triangulation",17.0,0.0,18.0,28.0,
29,0.6552259,0,1116,SciVis,2018,Labels on Levels: Labeling of Multi-Scale Multi-Instance and Crowded 3D Biological Environments,http://dx.doi.org/10.1109/TVCG.2018.2864491,"Labeling is intrinsically important for exploring and understanding complex environments and models in a variety of domains. We present a method for interactive labeling of crowded 3D scenes containing very many instances of objects spanning multiple scales in size. In contrast to previous labeling methods, we target cases where many instances of dozens of types are present and where the hierarchical structure of the objects in the scene presents an opportunity to choose the most suitable level for each placed label. Our solution builds on and goes beyond labeling techniques in medical 3D visualization, cartography, and biological illustrations from books and prints. In contrast to these techniques, the main characteristics of our new technique are: 1) a novel way of labeling objects as part of a bigger structure when appropriate, 2) visual clutter reduction by labeling only representative instances for each type of an object, and a strategy of selecting those. The appropriate level of label is chosen by analyzing the scene's depth buffer and the scene objects' hierarchy tree. We address the topic of communicating the parent-children relationship between labels by employing visual hierarchy concepts adapted from graphic design. Selecting representative instances considers several criteria tailored to the character of the data and is combined with a greedy optimization approach. We demonstrate the usage of our method with models from mesoscale biology where these two characteristics-multi-scale and multi-instance-are abundant, along with the fact that these scenes are extraordinarily dense.",David Kouril;Ladislav Cmolík;Barbora Kozlíková;Hsiang-Yun Wu;Graham Johnson;David S. Goodsell;Arthur J. Olson;M. Eduard Gröller;Ivan Viola,David Kouřil;Ladislav Čmolík;Barbora Kozlíková;Hslanc-Yun Wu;Graham Johnson;David S. Goodsell;Arthur Olson;M. Eduard Gröller;Ivan Viola,"TU Wien;Faculty of Electrical Engineering, Czech Technical University, Prague;Masaryk University;TU Wien;Allen Institute for Cell Science;The Scripps Research Institute;The Scripps Research Institute;TU Wien;TU Wien",10.1109/TVCG.2006.136;10.1109/TVCG.2008.168;10.1109/TVCG.2017.2744518,"labeling,multi-scale data,multi-instance data",,5.0,0.0,54.0,HM
30,0.6545376,0,348,InfoVis,2010,Perceptual Guidelines for Creating Rectangular Treemaps,http://dx.doi.org/10.1109/TVCG.2010.186,"Treemaps are space-filling visualizations that make efficient use of limited display space to depict large amounts of hierarchical data. Creating perceptually effective treemaps requires carefully managing a number of design parameters including the aspect ratio and luminance of rectangles. Moreover, treemaps encode values using area, which has been found to be less accurate than judgments of other visual encodings, such as length. We conduct a series of controlled experiments aimed at producing a set of design guidelines for creating effective rectangular treemaps. We find no evidence that luminance affects area judgments, but observe that aspect ratio does have an effect. Specifically, we find that the accuracy of area comparisons suffers when the compared rectangles have extreme aspect ratios or when both are squares. Contrary to common assumptions, the optimal distribution of rectangle aspect ratios within a treemap should include non-squares, but should avoid extremes. We then compare treemaps with hierarchical bar chart displays to identify the data densities at which length-encoded bar charts become less effective than area-encoded treemaps. We report the transition points at which treemaps exhibit judgment accuracy on par with bar charts for both leaf and non-leaf tree nodes. We also find that even at relatively low data densities treemaps result in faster comparisons than bar charts. Based on these results, we present a set of guidelines for the effective use of treemaps and suggest alternate approaches for treemap layout.",Nicholas Kong;Jeffrey Heer;Maneesh Agrawala,Nicholas Kong;Jeffrey Heer;Maneesh Agrawala,"University of California, Berkeley;Stanford University;University of California, Berkeley",10.1109/INFVIS.2000.885091;10.1109/INFVIS.2005.1532145;10.1109/INFVIS.2004.70;10.1109/INFVIS.2005.1532144;10.1109/TVCG.2007.70583;10.1109/INFVIS.2001.963283;10.1109/INFVIS.2001.963290;10.1109/TVCG.2008.171;10.1109/INFVIS.1999.801860;10.1109/INFVIS.2002.1173153,"Graphical Perception, Visualization, Treemaps, Rectangular Area, Visual Encoding, Experiment, Mechanical Turk",55.0,0.0,40.0,45.0,HM
31,0.65155584,0,1047,InfoVis,2017,Modeling Color Difference for Visualization Design,http://dx.doi.org/10.1109/TVCG.2017.2744359,"Color is frequently used to encode values in visualizations. For color encodings to be effective, the mapping between colors and values must preserve important differences in the data. However, most guidelines for effective color choice in visualization are based on either color perceptions measured using large, uniform fields in optimal viewing environments or on qualitative intuitions. These limitations may cause data misinterpretation in visualizations, which frequently use small, elongated marks. Our goal is to develop quantitative metrics to help people use color more effectively in visualizations. We present a series of crowdsourced studies measuring color difference perceptions for three common mark types: points, bars, and lines. Our results indicate that peoples' abilities to perceive color differences varies significantly across mark types. Probabilistic models constructed from the resulting data can provide objective guidance for designers, allowing them to anticipate viewer perceptions in order to inform effective encoding design.",Danielle Albers Szafir,Danielle Albers Szafir,University of Colorado,10.1109/VISUAL.1995.480803;10.1109/TVCG.2011.185;10.1109/TVCG.2010.154;10.1109/TVCG.2014.2346978;10.1109/TVCG.2016.2598918;10.1109/VISUAL.1996.568118;10.1109/TVCG.2011.194;10.1109/TVCG.2012.279;10.1109/TVCG.2016.2599106;10.1109/TVCG.2016.2599030;10.1109/TVCG.2008.118,"Color Perception,Graphical Perception,Color Models,Crowdsourcing",,32.0,18.0,55.0,BP
32,0.6411025,0,346,InfoVis,2010,Pargnostics: Screen-Space Metrics for Parallel Coordinates,http://dx.doi.org/10.1109/TVCG.2010.184,"Interactive visualization requires the translation of data into a screen space of limited resolution. While currently ignored by most visualization models, this translation entails a loss of information and the introduction of a number of artifacts that can be useful, (e.g., aggregation, structures) or distracting (e.g., over-plotting, clutter) for the analysis. This phenomenon is observed in parallel coordinates, where overlapping lines between adjacent axes form distinct patterns, representing the relation between variables they connect. However, even for a small number of dimensions, the challenge is to effectively convey the relationships for all combinations of dimensions. The size of the dataset and a large number of dimensions only add to the complexity of this problem. To address these issues, we propose Pargnostics, parallel coordinates diagnostics, a model based on screen-space metrics that quantify the different visual structures. Pargnostics metrics are calculated for pairs of axes and take into account the resolution of the display as well as potential axis inversions. Metrics include the number of line crossings, crossing angles, convergence, overplotting, etc. To construct a visualization view, the user can pick from a ranked display showing pairs of coordinate axes and the structures between them, or examine all possible combinations of axes at once in a matrix display. Picking the best axes layout is an NP-complete problem in general, but we provide a way of automatically optimizing the display according to the user's preferences based on our metrics and model.",Aritra Dasgupta;Robert Kosara,Aritra Dasgupta;Robert Kosara,University of North Carolina at Charlotte;University of North Carolina at Charlotte,10.1109/INFVIS.2005.1532142;10.1109/TVCG.2006.138;10.1109/VISUAL.1990.146402;10.1109/VAST.2006.261423;10.1109/VAST.2009.5332628;10.1109/INFVIS.2005.1532136;10.1109/INFVIS.1998.729559;10.1109/INFVIS.1997.636793,"Parallel coordinates, metrics, display optimization, visualization models",66.0,87.0,72.0,32.0,
33,0.6382506,0,754,InfoVis,2014,Learning Perceptual Kernels for Visualization Design,http://dx.doi.org/10.1109/TVCG.2014.2346978,"Visualization design can benefit from careful consideration of perception, as different assignments of visual encoding variables such as color, shape and size affect how viewers interpret data. In this work, we introduce perceptual kernels: distance matrices derived from aggregate perceptual judgments. Perceptual kernels represent perceptual differences between and within visual variables in a reusable form that is directly applicable to visualization evaluation and automated design. We report results from crowd-sourced experiments to estimate kernels for color, shape, size and combinations thereof. We analyze kernels estimated using five different judgment types-including Likert ratings among pairs, ordinal triplet comparisons, and manual spatial arrangement-and compare them to existing perceptual models. We derive recommendations for collecting perceptual similarities, and then demonstrate how the resulting kernels can be applied to automate visualization design decisions.",Çagatay Demiralp;Michael S. Bernstein;Jeffrey Heer,Çağatay Demiralp;Michael S. Bernstein;Jeffrey Heer,Stanford University;Stanford University;University of Washington,10.1109/TVCG.2010.186;10.1109/TVCG.2006.163;10.1109/TVCG.2007.70594;10.1109/TVCG.2011.167;10.1109/TVCG.2007.70583;10.1109/TVCG.2008.125;10.1109/TVCG.2010.130;10.1109/TVCG.2007.70539,"Visualization, design, encoding, perception, model, crowdsourcing, automated visualization, visual embedding",39.0,60.0,35.0,47.0,
34,0.6354208,0,90,InfoVis,2004,RecMap: Rectangular Map Approximations,http://dx.doi.org/10.1109/INFVIS.2004.57,"In many application domains, data is collected and referenced by its geospatial location. Nowadays, different kinds of maps are used to emphasize the spatial distribution of one or more geospatial attributes. The nature of geospatial statistical data is the highly nonuniform distribution in the real world data sets. This has several impacts on the resulting map visualizations. Classical area maps tend to highlight patterns in large areas, which may, however, be of low importance. Cartographers and geographers used cartograms or value-by-area maps to address this problem long before computers were available. Although many automatic techniques have been developed, most of the value-by-area cartograms are generated manually via human interaction. In this paper, we propose a novel visualization technique for geospatial data sets called RecMap. Our technique approximates a rectangular partition of the (rectangular) display area into a number of map regions preserving important geospatial constraints. It is a fully automatic technique with explicit user control over all exploration constraints within the exploration process. Experiments show that our technique produces visualizations of geospatial data sets, which enhance the discovery of global and local correlations, and demonstrate its performance in a variety of applications",Roland Heilmann;Daniel A. Keim;Christian Panse;Mike Sips,R. Heilmann;D.A. Keim;C. Panse;M. Sips,Bayer Technology,10.1109/VISUAL.1998.745303;10.1109/VISUAL.1991.175815;10.1109/INFVIS.2002.1173144,"Geographic Visualization, Information Visualization, Database and Data Mining Visualization",57.0,66.0,27.0,13.0,
35,0.63477546,0,42,InfoVis,2002,Angular brushing of extended parallel coordinates,http://dx.doi.org/10.1109/INFVIS.2002.1173157,"In this paper we present angular brushing for parallel coordinates (PC) as a new approach to highlighting rational data-properties, i.e., features which - in a non-separable way - depend on two data dimensions. We also demonstrate smooth brushing as an intuitive tool for specifying nonbinary degree-of-interest functions (for focus+context visualization). We also briefly describe our implementation as well as its application to the visualization of CFD data.",Helwig Hauser;Florian Ledermann;Helmut Doleisch,H. Hauser;F. Ledermann;H. Doleisch,"VRVis Res. Center, Vienna, Austria;VRVis Res. Center, Vienna, Austria;VRVis Res. Center, Vienna, Austria",10.1109/INFVIS.1996.559216;10.1109/VISUAL.2000.885739;10.1109/VISUAL.1994.346302;10.1109/VISUAL.1995.485139;10.1109/VISUAL.1990.146402,"information visualization, parallel coordinates, brushing, linear correlations, focus+context visualization",161.0,173.0,93.0,11.0,
36,0.63435215,0,1125,SciVis,2018,Gaia Sky: Navigating the Gaia Catalog,http://dx.doi.org/10.1109/TVCG.2018.2864508,"In this paper, we present Gaia Sky, a free and open-source multiplatform 3D Universe system, developed since 2014 in the Data Processing and Analysis Consortium framework of ESA's Gaia mission. Gaia's data release 2 represents the largest catalog of the stars of our Galaxy, comprising 1.3 billion star positions, with parallaxes, proper motions, magnitudes, and colors. In this mission, Gaia Sky is the central tool for off-the-shelf visualization of these data, and for aiding production of outreach material. With its capabilities to effectively handle these data, to enable seamless navigation along the high dynamic range of distances, and at the same time to provide advanced visualization techniques including relativistic aberration and gravitational wave effects, currently no actively maintained cross-platform, modern, and open alternative exists.",Antoni Sagristà;Stefan Jordan;Thomas Müller 0005;Filip Sadlo,Antoni Sagristà;Stefan Jordan;Thomas Müller;Filip Sadlo,Heidelberg University;Heidelberg University;Max Planck Institute for Astronomy;Heidelberg University,10.1109/TVCG.2006.176,"Astronomy visualization,3D Universe software,star catalog rendering,Gaia mission",0.0,2.0,3.0,31.0,
37,0.6339158,0,115,InfoVis,2005,Revealing structure within clustered parallel coordinates displays,http://dx.doi.org/10.1109/INFVIS.2005.1532138,"In order to gain insight into multivariate data, complex structures must be analysed and understood. Parallel coordinates is an excellent tool for visualizing this type of data but has its limitations. This paper deals with one of its main limitations - how to visualize a large number of data items without hiding the inherent structure they constitute. We solve this problem by constructing clusters and using high precision textures to represent them. We also use transfer functions that operate on the high precision textures in order to highlight different aspects of the cluster characteristics. Providing predefined transfer functions as well as the support to draw customized transfer functions makes it possible to extract different aspects of the data. We also show how feature animation can be used as guidance when simultaneously analysing several clusters. This technique makes it possible to visually represent statistical information about clusters and thus guides the user, making the analysis process more efficient.",Jimmy Johansson;Patric Ljung;Mikael Jern;Matthew D. Cooper,J. Johansson;P. Ljung;M. Jern;M. Cooper,"Norrkoping Visualization & Interaction Studio, Linkoping Univ., Sweden;Norrkoping Visualization & Interaction Studio, Linkoping Univ., Sweden;Norrkoping Visualization & Interaction Studio, Linkoping Univ., Sweden;Norrkoping Visualization & Interaction Studio, Linkoping Univ., Sweden",10.1109/VISUAL.1990.146402;10.1109/VISUAL.1999.809866;10.1109/INFVIS.2004.68,"Parallel coordinates, clustering, transfer function, feature animation",107.0,118.0,38.0,17.0,
38,0.63209105,0,1174,InfoVis,2018,Optimizing Color Assignment for Perception of Class Separability in Multiclass Scatterplots,http://dx.doi.org/10.1109/TVCG.2018.2864912,"Appropriate choice of colors significantly aids viewers in understanding the structures in multiclass scatterplots and becomes more important with a growing number of data points and groups. An appropriate color mapping is also an important parameter for the creation of an aesthetically pleasing scatterplot. Currently, users of visualization software routinely rely on color mappings that have been pre-defined by the software. A default color mapping, however, cannot ensure an optimal perceptual separability between groups, and sometimes may even lead to a misinterpretation of the data. In this paper, we present an effective approach for color assignment based on a set of given colors that is designed to optimize the perception of scatterplots. Our approach takes into account the spatial relationships, density, degree of overlap between point clusters, and also the background color. For this purpose, we use a genetic algorithm that is able to efficiently find good color assignments. We implemented an interactive color assignment system with three extensions of the basic method that incorporates top K suggestions, user-defined color subsets, and classes of interest for the optimization. To demonstrate the effectiveness of our assignment technique, we conducted a numerical study and a controlled user study to compare our approach with default color assignments; our findings were verified by two expert studies. The results show that our approach is able to support users in distinguishing cluster numbers faster and more precisely than default assignment methods.",Yunhai Wang;Xin Chen;Tong Ge;Chen Bao;Michael Sedlmair;Chi-Wing Fu;Oliver Deussen;Baoquan Chen,Yunhai Wang;Xin Chen;Tong Ge;Chen Bao;Michael Sedlmair;Chi-Wing Fu;Oliver Deussen;Baoquan Chen,"Shandong University;Shandong University;Shandong University;Shandong University;VISUS, University of Stuttgart, Germany;Chinese University, Hong Kong;Konstanz University, Germany;Peking University",10.1109/VISUAL.1995.480803;10.1109/TVCG.2016.2599214;10.1109/TVCG.2013.183;10.1109/TVCG.2016.2598918;10.1109/VISUAL.1996.568118;10.1109/TVCG.2017.2744184;10.1109/TVCG.2013.153;10.1109/TVCG.2015.2467471;10.1109/TVCG.2017.2744359;10.1109/VAST.2009.5332628;10.1109/TVCG.2008.118,"Color perception,visual design,scatterplots",0.0,1.0,5.0,50.0,
39,0.63136286,0,55,InfoVis,2003,"Interactive hierarchical dimension ordering, spacing and filtering for exploration of high dimensional datasets",http://dx.doi.org/10.1109/INFVIS.2003.1249015,"Large number of dimensions not only cause clutter in multi-dimensional visualizations, but also make it difficult for users to navigate the data space. Effective dimension management, such as dimension ordering, spacing and filtering, is critical for visual exploration of such datasets. Dimension ordering and spacing explicitly reveal dimension relationships in arrangement-sensitive multidimensional visualization techniques, such as parallel coordinates, star glyphs, and pixel-oriented techniques. They facilitate the visual discovery of patterns within the data. Dimension filtering hides some of the dimensions to reduce clutter while preserving the major information of the dataset. In this paper, we propose an interactive hierarchical dimension ordering, spacing and filtering approach, called DOSFA. DOSFA is based on dimension hierarchies derived from similarities among dimensions. It is scalable multi-resolution approach making dimensional management a tractable task. On the one hand, it automatically generates default settings for dimension ordering, spacing and filtering. On the other hand, it allows users to efficiently control all aspects of this dimension management process via visual interaction tools for dimension hierarchy manipulation. A case study visualizing a dataset containing over 200 dimensions reveals high dimensional visualization techniques.",Jing Yang 0001;Wei Peng;Matthew O. Ward;Elke A. Rundensteiner,Jing Yang;Wei Peng;M.O. Ward;E.A. Rundensteiner,"Dept. of comuter Sci., Worcester Polytech. Inst., MA, USA;Dept. of comuter Sci., Worcester Polytech. Inst., MA, USA;Dept. of comuter Sci., Worcester Polytech. Inst., MA, USA;Dept. of comuter Sci., Worcester Polytech. Inst., MA, USA",10.1109/VISUAL.1990.146386;10.1109/VISUAL.1990.146402;10.1109/INFVIS.1998.729559;10.1109/VISUAL.1994.346302;10.1109/INFVIS.2000.885086;10.1109/VISUAL.1995.485140;10.1109/INFVIS.2002.1173151,"Dimension ordering, dimension spacing, dimension filtering, multidimensional visualization, high dimensional datasets",111.0,128.0,18.0,24.0,
40,0.63079053,0,388,InfoVis,2011,Arc Length-Based Aspect Ratio Selection,http://dx.doi.org/10.1109/TVCG.2011.167,"The aspect ratio of a plot has a dramatic impact on our ability to perceive trends and patterns in the data. Previous approaches for automatically selecting the aspect ratio have been based on adjusting the orientations or angles of the line segments in the plot. In contrast, we recommend a simple, effective method for selecting the aspect ratio: minimize the arc length of the data curve while keeping the area of the plot constant. The approach is parameterization invariant, robust to a wide range of inputs, preserves visual symmetries in the data, and is a compromise between previously proposed techniques. Further, we demonstrate that it can be effectively used to select the aspect ratio of contour plots. We believe arc length should become the default aspect ratio selection method.",Justin Talbot;John Gerth;Pat Hanrahan,Justin Talbot;John Gerth;Pat Hanrahan,Stanford University;Stanford University;Stanford University,10.1109/TVCG.2006.163,"Aspect ratio selection, Banking to 45 degrees, Orientation resolution",14.0,23.0,13.0,17.0,
41,0.628422,0,139,InfoVis,2006,Measuring Data Abstraction Quality in Multiresolution Visualizations,http://dx.doi.org/10.1109/TVCG.2006.161,"Data abstraction techniques are widely used in multiresolution visualization systems to reduce visual clutter and facilitate analysis from overview to detail. However, analysts are usually unaware of how well the abstracted data represent the original dataset, which can impact the reliability of results gleaned from the abstractions. In this paper, we define two data abstraction quality measures for computing the degree to which the abstraction conveys the original dataset: the histogram difference measure and the nearest neighbor measure. They have been integrated within XmdvTool, a public-domain multiresolution visualization system for multivariate data analysis that supports sampling as well as clustering to simplify data. Several interactive operations are provided, including adjusting the data abstraction level, changing selected regions, and setting the acceptable data abstraction quality level. Conducting these operations, analysts can select an optimal data abstraction level. Also, analysts can compare different abstraction methods using the measures to see how well relative data density and outliers are maintained, and then select an abstraction method that meets the requirement of their analytic tasks",Qingguang Cui;Matthew O. Ward;Elke A. Rundensteiner;Jing Yang 0001,Qingguang Cui;Matthew Ward;Elke Rundensteiner;Jing Yang,"Worcester Polytechnic Institute, 100 Institute Road, Worcester, MA 01609;Worcester Polytechnic Institute, 100 Institute Road, Worcester, MA 01609;Worcester Polytechnic Institute, 100 Institute Road, Worcester, MA 01609;University of North Carolina at Charlotte, 9201 University City Blvd, Charlotte, NC 28223",10.1109/INFVIS.2004.19;10.1109/VISUAL.2005.1532819;10.1109/INFVIS.2004.15;10.1109/VISUAL.1995.485139;10.1109/INFVIS.2000.885088,"Metrics, Clustering, Sampling, Multiresolution Visualization",55.0,0.0,46.0,28.0,
42,0.6283047,0,496,SciVis,2012,Interactive Volume Exploration of Petascale Microscopy Data Streams Using a Visualization-Driven Virtual Memory Approach,http://dx.doi.org/10.1109/TVCG.2012.240,"This paper presents the first volume visualization system that scales to petascale volumes imaged as a continuous stream of high-resolution electron microscopy images. Our architecture scales to dense, anisotropic petascale volumes because it: (1) decouples construction of the 3D multi-resolution representation required for visualization from data acquisition, and (2) decouples sample access time during ray-casting from the size of the multi-resolution hierarchy. Our system is designed around a scalable multi-resolution virtual memory architecture that handles missing data naturally, does not pre-compute any 3D multi-resolution representation such as an octree, and can accept a constant stream of 2D image tiles from the microscopes. A novelty of our system design is that it is visualization-driven: we restrict most computations to the visible volume data. Leveraging the virtual memory architecture, missing data are detected during volume ray-casting as cache misses, which are propagated backwards for on-demand out-of-core processing. 3D blocks of volume data are only constructed from 2D microscope image tiles when they have actually been accessed during ray-casting. We extensively evaluate our system design choices with respect to scalability and performance, compare to previous best-of-breed systems, and illustrate the effectiveness of our system for real microscopy data from neuroscience.",Markus Hadwiger;Johanna Beyer;Won-Ki Jeong;Hanspeter Pfister,Markus Hadwiger;Johanna Beyer;Won-Ki Jeong;Hanspeter Pfister,"King Adbullah University of Science and Technology, Saudi Arabia;King Adbullah University of Science and Technology, Saudi Arabia;UNIST;Harvard University",10.1109/VISUAL.1999.809908;10.1109/VISUAL.2003.1250384;10.1109/TVCG.2009.161,"Petascale volume exploration, high-resolution microscopy, high-throughput imaging, neuroscience",42.0,51.0,41.0,31.0,HM
43,0.6273888,0,997,SciVis,2016,Categorical Colormap Optimization with Visualization Case Studies,http://dx.doi.org/10.1109/TVCG.2016.2599214,"Mapping a set of categorical values to different colors is an elementary technique in data visualization. Users of visualization software routinely rely on the default colormaps provided by a system, or colormaps suggested by software such as ColorBrewer. In practice, users often have to select a set of colors in a semantically meaningful way (e.g., based on conventions, color metaphors, and logological associations), and consequently would like to ensure their perceptual differentiation is optimized. In this paper, we present an algorithmic approach for maximizing the perceptual distances among a set of given colors. We address two technical problems in optimization, i.e., (i) the phenomena of local maxima that halt the optimization too soon, and (ii) the arbitrary reassignment of colors that leads to the loss of the original semantic association. We paid particular attention to different types of constraints that users may wish to impose during the optimization process. To demonstrate the effectiveness of this work, we tested this technique in two case studies. To reach out to a wider range of users, we also developed a web application called Colourmap Hospital.",Hui Fang;Simon J. Walton;E. Delahaye;J. Harris;D. A. Storchak;Min Chen 0001,H. Fang;S. Walton;E. Delahaye;J. Harris;D. A. Storchak;M. Chen,"University of Oxford and International Seismological Centre;University of Oxford, UK;International Seismological Centre, UK;International Seismological Centre, UK;International Seismological Centre, UK;University of Oxford, UK",10.1109/VISUAL.1996.568118;10.1109/TVCG.2014.2346978;10.1109/TVCG.2008.112;10.1109/VISUAL.1995.480803;10.1109/TVCG.2010.150;10.1109/VISUAL.2002.1183788;10.1109/TVCG.2008.118,London tube map;Color;categorical colormap;optimization;seismological data visualization,1.0,5.0,6.0,53.0,
44,0.6265651,0,690,SciVis,2014,Advection-Based Sparse Data Management for Visualizing Unsteady Flow,http://dx.doi.org/10.1109/TVCG.2014.2346418,"When computing integral curves and integral surfaces for large-scale unsteady flow fields, a major bottleneck is the widening gap between data access demands and the available bandwidth (both I/O and in-memory). In this work, we explore a novel advection-based scheme to manage flow field data for both efficiency and scalability. The key is to first partition flow field into blocklets (e.g. cells or very fine-grained blocks of cells), and then (pre)fetch and manage blocklets on-demand using a parallel key-value store. The benefits are (1) greatly increasing the scale of local-range analysis (e.g. source-destination queries, streak surface generation) that can fit within any given limit of hardware resources; (2) improving memory and I/O bandwidth-efficiencies as well as the scalability of naive task-parallel particle advection. We demonstrate our method using a prototype system that works on workstation and also in supercomputing environments. Results show significantly reduced I/O overhead compared to accessing raw flow data, and also high scalability on a supercomputer for a variety of applications.",Hanqi Guo;Jiang Zhang;Richen Liu;Lu Liu;Xiaoru Yuan;Jian Huang 0007;Xiangfei Meng;Jingshan Pan,Hanqi Guo;Jiang Zhang;Richen Liu;Lu Liu;Xiaoru Yuan;Jian Huang;Xiangfei Meng;Jingshan Pan,"Key Laboratory of Machine Perception (Ministry of Education), School of EECS;Key Laboratory of Machine Perception (Ministry of Education), School of EECS;Key Laboratory of Machine Perception (Ministry of Education), School of EECS;Key Laboratory of Machine Perception (Ministry of Education), School of EECS;Key Laboratory of Machine Perception (Ministry of Education), School of EECS;Department of Electrical Engineering and Computer Science, University of Tennessee, Knoxville;National Supercomputer Center in Tianjin, Binhai, Tianjin, China;National Supercomputer Center in Jinan, Shandong, China",10.1109/TVCG.2009.154;10.1109/TVCG.2011.219;10.1109/VISUAL.1997.663898;10.1109/TVCG.2013.144;10.1109/TVCG.2013.128;10.1109/TVCG.2007.70551,"Flow visualization, Data management, High performance visualization, Key-value store",9.0,14.0,12.0,37.0,
45,0.6260313,0,246,InfoVis,2008,Rolling the Dice: Multidimensional Visual Exploration using Scatterplot Matrix Navigation,http://dx.doi.org/10.1109/TVCG.2008.153,"Scatterplots remain one of the most popular and widely-used visual representations for multidimensional data due to their simplicity, familiarity and visual clarity, even if they lack some of the flexibility and visual expressiveness of newer multidimensional visualization techniques. This paper presents new interactive methods to explore multidimensional data using scatterplots. This exploration is performed using a matrix of scatterplots that gives an overview of the possible configurations, thumbnails of the scatterplots, and support for interactive navigation in the multidimensional space. Transitions between scatterplots are performed as animated rotations in 3D space, somewhat akin to rolling dice. Users can iteratively build queries using bounding volumes in the dataset, sculpting the query from different viewpoints to become more and more refined. Furthermore, the dimensions in the navigation space can be reordered, manually or automatically, to highlight salient correlations and differences among them. An example scenario presents the interaction techniques supporting smooth and effortless visual exploration of multidimensional datasets.",Niklas Elmqvist;Pierre Dragicevic;Jean-Daniel Fekete,Niklas Elmqvist;Pierre Dragicevic;Jean-Daniel Fekete,,10.1109/TVCG.2007.70515;10.1109/VAST.2007.4389013;10.1109/TVCG.2007.70577;10.1109/VISUAL.1990.146386;10.1109/VAST.2006.261452;10.1109/INFVIS.2005.1532136;10.1109/VISUAL.1994.346302;10.1109/INFVIS.1998.729559;10.1109/VISUAL.1995.485139;10.1109/INFVIS.2003.1249016;10.1109/INFVIS.2000.885086;10.1109/INFVIS.2004.3;10.1109/INFVIS.2004.64;10.1109/TVCG.2007.70539;10.1109/INFVIS.2004.15,"Visual exploration, visual queries, visual analytics, navigation, multivariate data, interaction",251.0,285.0,174.0,42.0,BP
46,0.6249337,0,417,InfoVis,2011,Product Plots,http://dx.doi.org/10.1109/TVCG.2011.227,"We propose a new framework for visualising tables of counts, proportions and probabilities. We call our framework product plots, alluding to the computation of area as a product of height and width, and the statistical concept of generating a joint distribution from the product of conditional and marginal distributions. The framework, with extensions, is sufficient to encompass over 20 visualisations previously described in fields of statistical graphics and infovis, including bar charts, mosaic plots, treemaps, equal area plots and fluctuation diagrams.",Hadley Wickham;Heike Hofmann,Hadley Wickham;Heike Hofmann,Rice University;Iowa State University,10.1109/TVCG.2007.70594;10.1109/TVCG.2006.200;10.1109/INFVIS.2002.1173141;10.1109/INFVIS.2000.885091;10.1109/VISUAL.1990.146386;10.1109/TVCG.2010.186;10.1109/INFVIS.2005.1532128;10.1109/INFVIS.2005.1532142;10.1109/TVCG.2010.209;10.1109/TVCG.2009.128;10.1109/INFVIS.2005.1532145,"Statistics, joint distribution, conditional distribution, treemap, bar chart, mosaic plot",26.0,30.0,22.0,52.0,
47,0.6228132,0,1020,SciVis,2017,Dynamic Load Balancing Based on Constrained K-D Tree Decomposition for Parallel Particle Tracing,http://dx.doi.org/10.1109/TVCG.2017.2744059,"We propose a dynamically load-balanced algorithm for parallel particle tracing, which periodically attempts to evenly redistribute particles across processes based on k-d tree decomposition. Each process is assigned with (1) a statically partitioned, axis-aligned data block that partially overlaps with neighboring blocks in other processes and (2) a dynamically determined k-d tree leaf node that bounds the active particles for computation; the bounds of the k-d tree nodes are constrained by the geometries of data blocks. Given a certain degree of overlap between blocks, our method can balance the number of particles as much as possible. Compared with other load-balancing algorithms for parallel particle tracing, the proposed method does not require any preanalysis, does not use any heuristics based on flow features, does not make any assumptions about seed distribution, does not move any data blocks during the run, and does not need any master process for work redistribution. Based on a comprehensive performance study up to 8K processes on a Blue Gene/Q system, the proposed algorithm outperforms baseline approaches in both load balance and scalability on various flow visualization and analysis problems.",Jiang Zhang;Hanqi Guo;Fan Hong;Xiaoru Yuan;Tom Peterka,Jiang Zhang;Hanqi Guo;Fan Hong;Xiaoru Yuan;Tom Peterka,"Ministry of EducationKey Laboratory of Machine PerceptionSchool of EECSPeking University;Mathematics and Computer Science Division, Argonne National Laboratory, Lemont, IL, USA;Ministry of EducationKey Laboratory of Machine PerceptionSchool of EECSPeking University;Ministry of EducationKey Laboratory of Machine PerceptionSchool of EECSPeking University;Mathematics and Computer Science Division, Argonne National Laboratory, Lemont, IL, USA",10.1109/TVCG.2013.128;10.1109/TVCG.2007.70551;10.1109/TVCG.2013.144;10.1109/TVCG.2011.219;10.1109/VISUAL.1997.663898;10.1109/TVCG.2017.2744059,"Parallel particle tracing,dynamic load balancing,k-d trees,performance analysis",1.0,5.0,5.0,37.0,
48,0.6215063,0,27,InfoVis,1999,Cushion treemaps: visualization of hierarchical information,http://dx.doi.org/10.1109/INFVIS.1999.801860,"A new method is presented for the visualization of hierarchical information, such as directory structures and organization structures. Cushion treemaps inherit the elegance of standard treemaps: compact, space-filling displays of hierarchical information, based on recursive subdivision of a rectangular image space. Intuitive shading is used to provide insight in the hierarchical structure. During the subdivision, ridges are added per rectangle, which are rendered with a simple shading model. The result is a surface that consists of recursive cushions. The method is efficient, effective, easy to use and implement, and has a wide applicability.",Jarke J. van Wijk;Huub van de Wetering,J.J. Van Wijk;H. Van de Wetering,"Dept. of Math. & Comput. Sci., Eindhoven Univ. of Technol., Netherlands",10.1109/VISUAL.1991.175815,"Information Visualization, Tree Visualization, Treemaps",186.0,211.0,81.0,11.0,
49,0.61642003,0,585,VAST,2013,Explainers: Expert Explorations with Crafted Projections,http://dx.doi.org/10.1109/TVCG.2013.157,"This paper introduces an approach to exploration and discovery in high-dimensional data that incorporates a user's knowledge and questions to craft sets of projection functions meaningful to them. Unlike most prior work that defines projections based on their statistical properties, our approach creates projection functions that align with user-specified annotations. Therefore, the resulting derived dimensions represent concepts defined by the user's examples. These especially crafted projection functions, or explainers, can help find and explain relationships between the data variables and user-designated concepts. They can organize the data according to these concepts. Sets of explainers can provide multiple perspectives on the data. Our approach considers tradeoffs in choosing these projection functions, including their simplicity, expressive power, alignment with prior knowledge, and diversity. We provide techniques for creating collections of explainers. The methods, based on machine learning optimization frameworks, allow exploring the tradeoffs. We demonstrate our approach on model problems and applications in text analysis.",Michael Gleicher,Michael Gleicher,"Department of Computer Sciences, University of Wisconsin - Madison",10.1109/VAST.2012.6400487;10.1109/VAST.2012.6400486;10.1109/TVCG.2012.277;10.1109/INFVIS.2005.1532142;10.1109/INFVIS.2004.71;10.1109/TVCG.2012.256;10.1109/VAST.2010.5652392;10.1109/VAST.2012.6400490;10.1109/TVCG.2011.220;10.1109/INFVIS.1998.729559;10.1109/VAST.2011.6102448;10.1109/TVCG.2009.153,"High-dimensional spaces, exploration, support vector machines",27.0,39.0,26.0,51.0,HM
50,0.6162555,0,414,InfoVis,2011,Local Affine Multidimensional Projection,http://dx.doi.org/10.1109/TVCG.2011.220,"Multidimensional projection techniques have experienced many improvements lately, mainly regarding computational times and accuracy. However, existing methods do not yet provide flexible enough mechanisms for visualization-oriented fully interactive applications. This work presents a new multidimensional projection technique designed to be more flexible and versatile than other methods. This novel approach, called Local Affine Multidimensional Projection (LAMP), relies on orthogonal mapping theory to build accurate local transformations that can be dynamically modified according to user knowledge. The accuracy, flexibility and computational efficiency of LAMP is confirmed by a comprehensive set of comparisons. LAMP's versatility is exploited in an application which seeks to correlate data that, in principle, has no connection as well as in visual exploration of textual documents.",Paulo Joia;Danilo Barbosa Coimbra;José Alberto Cuminato;Fernando Vieira Paulovich;Luis Gustavo Nonato,Paulo Joia;Danilo Coimbra;Jose A. Cuminato;Fernando V. Paulovich;Luis G. Nonato,Universidade de S&#x0E3;o Paulo (USP);Universidade de S&#x0E3;o Paulo (USP);Universidade de S&#x0E3;o Paulo (USP);Universidade de S&#x0E3;o Paulo (USP);Universidade de S&#x0E3;o Paulo (USP),10.1109/VISUAL.1996.567787;10.1109/TVCG.2009.140;10.1109/TVCG.2007.70580;10.1109/INFVIS.2002.1173159;10.1109/TVCG.2010.207;10.1109/TVCG.2010.170;10.1109/INFVIS.2002.1173161,"Multidimensional Projection, High Dimensional Data, Visual Data Mining",84.0,0.0,98.0,36.0,HM
